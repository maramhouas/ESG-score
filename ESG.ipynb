{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cae08870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import PyPDF2\n",
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "import wordcloud\n",
    "import mlflow\n",
    "import sklearn\n",
    "import string\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79672598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(url):\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "        open_pdf_file = io.BytesIO(response.content)\n",
    "        pdf = PyPDF2.PdfReader(open_pdf_file)\n",
    "        \n",
    "        # Access pdf content \n",
    "        text = []\n",
    "        for i in range(len(pdf.pages)):\n",
    "            page = pdf.pages[i]\n",
    "            text.append(page.extract_text())\n",
    "        \n",
    "        # Return concatenated content \n",
    "        return \"\\n\".join(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing {url}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bf99b2b3-df3f-4e93-b8c4-bf85ea15f5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef clean_esg_report_urls(urls):\\n    cleaned_urls = []\\n    for url in set(urls):\\n        try:\\n            response = requests.get(url)\\n            if response.status_code == 200:\\n                cleaned_urls.append(url)\\n        except:\\n            pass\\n    return cleaned_urls\\ncleaned_urls = clean_esg_report_urls(urls)\\nprint(cleaned_urls)\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def clean_esg_report_urls(urls):\n",
    "    cleaned_urls = []\n",
    "    for url in set(urls):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                cleaned_urls.append(url)\n",
    "        except:\n",
    "            pass\n",
    "    return cleaned_urls\n",
    "cleaned_urls = clean_esg_report_urls(urls)\n",
    "print(cleaned_urls)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e45daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_urls={ \n",
    "  'barclays': 'https://www.responsibilityreports.com/HostedData/ResponsibilityReports/PDF/LSE_BARC_2021.pdf',\n",
    "  'jp morgan chase': 'https://www.jpmorgan.com/content/dam/jpmc/jpmorgan-chase-and-co/documents/jpmc-esg-report-2021.pdf',\n",
    "  'BNP Paribas': 'https://cdn-group.bnpparibas.com/uploads/file/bnpp_climateanalytics_alignmentreport_final.pdf',\n",
    "  'goldman sachs': 'https://www.goldmansachs.com/a/2021-sustainability-report.pdf',\n",
    "  'hsbc': 'https://www.hsbc.com/-/files/hsbc/investors/hsbc-results/2021/annual/pdfs/hsbc-holdings-plc/220222-esg-review-2021.pdf',\n",
    "  'PNC':'https://www.pnc.com/content/dam/pnc-com/pdf/aboutpnc/CorporateResponsibilityReports/PNC_Corporate_Responsibility_Report_2021.pdf',\n",
    "  'bank of america': 'https://about.bankofamerica.com/content/dam/about/pdfs/ESG_GHI_2021_508_secured.pdf',\n",
    "  'rbc': 'https://www.rbc.com/community-social-impact/_assets-custom/pdf/2021-ESG-Report.PDF',\n",
    "  'macquarie': 'https://www.macquarie.com/assets/macq/investor/reports/2021/sections/macquarie-group-fy21-esg.pdf',\n",
    "  'lloyds': 'https://assets.lloyds.com/media/8c362b67-e4a5-4876-927f-397c10491d72/Lloyds_ESG%202021_report_final.pdf',\n",
    "  'santander': 'https://www.santander.com/content/dam/santander-com/en/contenido-paginas/nuestro-compromiso/reports/doc-informe-BR-polonia-2021.pdf',\n",
    "  'bluebay': 'https://www.rbcbluebay.com/globalassets/documents/bluebay-esg-investment-update-june-2021.pdf',\n",
    "  'riverstone': 'https://www.riverstonellc.com/media/1328/riverstone-esg-report-2021_updated.pdf',\n",
    "  'aberdeen standard': 'https://www.abrdn.com/docs?documentId=GB-080322-167278-5',\n",
    "  'apollo': 'https://www.apollo.com/~/media/Files/A/Apollo-V3/documents/apollo-2021-esg-report-final.pdf',\n",
    "  'vanguard': 'https://www.nl.vanguard/content/dam/intl/europe/documents/en/climate-change-tcfd-report_en-eu.pdf',\n",
    "  'ruffer': 'https://www.ruffer.co.uk/-/media/ruffer-website/files/downloads/cat/2021-cat-responsible-investment-report.pdf?la=en&hash=2EB1AE3E432C88D6E51015A3079A5D09',\n",
    "         }\n",
    "# Prepare PDF into Dataframe\n",
    "esg_urls_pd = pd.DataFrame(list(esg_urls.items()), columns=['company', 'url'])\n",
    "\n",
    "esg_urls = pd.DataFrame(esg_urls_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "41125e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barclays</td>\n",
       "      <td>https://www.responsibilityreports.com/HostedDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jp morgan chase</td>\n",
       "      <td>https://www.jpmorgan.com/content/dam/jpmc/jpmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BNP Paribas</td>\n",
       "      <td>https://cdn-group.bnpparibas.com/uploads/file/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goldman sachs</td>\n",
       "      <td>https://www.goldmansachs.com/a/2021-sustainabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hsbc</td>\n",
       "      <td>https://www.hsbc.com/-/files/hsbc/investors/hs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PNC</td>\n",
       "      <td>https://www.pnc.com/content/dam/pnc-com/pdf/ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bank of america</td>\n",
       "      <td>https://about.bankofamerica.com/content/dam/ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbc</td>\n",
       "      <td>https://www.rbc.com/community-social-impact/_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>macquarie</td>\n",
       "      <td>https://www.macquarie.com/assets/macq/investor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lloyds</td>\n",
       "      <td>https://assets.lloyds.com/media/8c362b67-e4a5-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>santander</td>\n",
       "      <td>https://www.santander.com/content/dam/santande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bluebay</td>\n",
       "      <td>https://www.rbcbluebay.com/globalassets/docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>riverstone</td>\n",
       "      <td>https://www.riverstonellc.com/media/1328/river...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aberdeen standard</td>\n",
       "      <td>https://www.abrdn.com/docs?documentId=GB-08032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>apollo</td>\n",
       "      <td>https://www.apollo.com/~/media/Files/A/Apollo-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vanguard</td>\n",
       "      <td>https://www.nl.vanguard/content/dam/intl/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ruffer</td>\n",
       "      <td>https://www.ruffer.co.uk/-/media/ruffer-websit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              company                                                url\n",
       "0            barclays  https://www.responsibilityreports.com/HostedDa...\n",
       "1     jp morgan chase  https://www.jpmorgan.com/content/dam/jpmc/jpmo...\n",
       "2         BNP Paribas  https://cdn-group.bnpparibas.com/uploads/file/...\n",
       "3       goldman sachs  https://www.goldmansachs.com/a/2021-sustainabi...\n",
       "4                hsbc  https://www.hsbc.com/-/files/hsbc/investors/hs...\n",
       "5                 PNC  https://www.pnc.com/content/dam/pnc-com/pdf/ab...\n",
       "6     bank of america  https://about.bankofamerica.com/content/dam/ab...\n",
       "7                 rbc  https://www.rbc.com/community-social-impact/_a...\n",
       "8           macquarie  https://www.macquarie.com/assets/macq/investor...\n",
       "9              lloyds  https://assets.lloyds.com/media/8c362b67-e4a5-...\n",
       "10          santander  https://www.santander.com/content/dam/santande...\n",
       "11            bluebay  https://www.rbcbluebay.com/globalassets/docume...\n",
       "12         riverstone  https://www.riverstonellc.com/media/1328/river...\n",
       "13  aberdeen standard  https://www.abrdn.com/docs?documentId=GB-08032...\n",
       "14             apollo  https://www.apollo.com/~/media/Files/A/Apollo-...\n",
       "15           vanguard  https://www.nl.vanguard/content/dam/intl/europ...\n",
       "16             ruffer  https://www.ruffer.co.uk/-/media/ruffer-websit..."
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esg_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b4874249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while processing https://www.responsibilityreports.com/HostedData/ResponsibilityReports/PDF/LSE_BARC_2021.pdf: EOF marker not found\n",
      "Error occurred while processing https://www.pnc.com/content/dam/pnc-com/pdf/aboutpnc/CorporateResponsibilityReports/PNC_Corporate_Responsibility_Report_2021.pdf: EOF marker not found\n",
      "Error occurred while processing https://about.bankofamerica.com/content/dam/about/pdfs/ESG_GHI_2021_508_secured.pdf: PyCryptodome is required for AES algorithm\n",
      "Error occurred while processing https://www.rbcbluebay.com/globalassets/documents/bluebay-esg-investment-update-june-2021.pdf: EOF marker not found\n",
      "Error occurred while processing https://www.apollo.com/~/media/Files/A/Apollo-V3/documents/apollo-2021-esg-report-final.pdf: EOF marker not found\n"
     ]
    }
   ],
   "source": [
    "# add a new column to the data frame esg_urls_pd with the name 'content'\n",
    "\n",
    "esg_urls_pd['content'] = esg_urls_pd['url'].apply(extract_content)\n",
    "esg_articles = esg_urls_pd[esg_urls_pd['content'].str.len() > 0] # that only includes rows with non-empty content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d17fd0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jp morgan chase</td>\n",
       "      <td>https://www.jpmorgan.com/content/dam/jpmc/jpmo...</td>\n",
       "      <td>2021  \\nENVIRONMENTAL  \\nSOCIAL &amp;  \\nGOVERNAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BNP Paribas</td>\n",
       "      <td>https://cdn-group.bnpparibas.com/uploads/file/...</td>\n",
       "      <td>1\\nBNP PARIBAS / CLIMATE ANALYTICS AND ALIGNM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goldman sachs</td>\n",
       "      <td>https://www.goldmansachs.com/a/2021-sustainabi...</td>\n",
       "      <td>Progress \\nThrough \\nPerformanceSUSTAINABILITY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hsbc</td>\n",
       "      <td>https://www.hsbc.com/-/files/hsbc/investors/hs...</td>\n",
       "      <td>Environmental, social \\nand governance review\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbc</td>\n",
       "      <td>https://www.rbc.com/community-social-impact/_a...</td>\n",
       "      <td>HNW_NRG_B_Bleed_NoMask\\nRoyal Bank of Canada\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>macquarie</td>\n",
       "      <td>https://www.macquarie.com/assets/macq/investor...</td>\n",
       "      <td>52\\nEnvironmental, Social and Governance\\nMacq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lloyds</td>\n",
       "      <td>https://assets.lloyds.com/media/8c362b67-e4a5-...</td>\n",
       "      <td>Environmental, Social \\nand Governance \\nRepor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>santander</td>\n",
       "      <td>https://www.santander.com/content/dam/santande...</td>\n",
       "      <td>ESG Report 2021\\nLooking to the future\\nRespon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>riverstone</td>\n",
       "      <td>https://www.riverstonellc.com/media/1328/river...</td>\n",
       "      <td>Investing  \\nResponsibly\\nRiverstone ESG Repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aberdeen standard</td>\n",
       "      <td>https://www.abrdn.com/docs?documentId=GB-08032...</td>\n",
       "      <td>The Power  \\nof Investment\\nSustainability Rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vanguard</td>\n",
       "      <td>https://www.nl.vanguard/content/dam/intl/europ...</td>\n",
       "      <td>Vanguard’s Report \\non Climate-related \\nImpac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ruffer</td>\n",
       "      <td>https://www.ruffer.co.uk/-/media/ruffer-websit...</td>\n",
       "      <td>Responsible \\nInvestment \\nReport \\n2021\\nCHAR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              company                                                url  \\\n",
       "1     jp morgan chase  https://www.jpmorgan.com/content/dam/jpmc/jpmo...   \n",
       "2         BNP Paribas  https://cdn-group.bnpparibas.com/uploads/file/...   \n",
       "3       goldman sachs  https://www.goldmansachs.com/a/2021-sustainabi...   \n",
       "4                hsbc  https://www.hsbc.com/-/files/hsbc/investors/hs...   \n",
       "7                 rbc  https://www.rbc.com/community-social-impact/_a...   \n",
       "8           macquarie  https://www.macquarie.com/assets/macq/investor...   \n",
       "9              lloyds  https://assets.lloyds.com/media/8c362b67-e4a5-...   \n",
       "10          santander  https://www.santander.com/content/dam/santande...   \n",
       "12         riverstone  https://www.riverstonellc.com/media/1328/river...   \n",
       "13  aberdeen standard  https://www.abrdn.com/docs?documentId=GB-08032...   \n",
       "15           vanguard  https://www.nl.vanguard/content/dam/intl/europ...   \n",
       "16             ruffer  https://www.ruffer.co.uk/-/media/ruffer-websit...   \n",
       "\n",
       "                                              content  \n",
       "1    2021  \\nENVIRONMENTAL  \\nSOCIAL &  \\nGOVERNAN...  \n",
       "2    1\\nBNP PARIBAS / CLIMATE ANALYTICS AND ALIGNM...  \n",
       "3   Progress \\nThrough \\nPerformanceSUSTAINABILITY...  \n",
       "4   Environmental, social \\nand governance review\\...  \n",
       "7   HNW_NRG_B_Bleed_NoMask\\nRoyal Bank of Canada\\n...  \n",
       "8   52\\nEnvironmental, Social and Governance\\nMacq...  \n",
       "9   Environmental, Social \\nand Governance \\nRepor...  \n",
       "10  ESG Report 2021\\nLooking to the future\\nRespon...  \n",
       "12  Investing  \\nResponsibly\\nRiverstone ESG Repor...  \n",
       "13  The Power  \\nof Investment\\nSustainability Rep...  \n",
       "15  Vanguard’s Report \\non Climate-related \\nImpac...  \n",
       "16  Responsible \\nInvestment \\nReport \\n2021\\nCHAR...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esg_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a7570dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "    \"\"\"\n",
    "    Removes non-ASCII characters from the given text\n",
    "    \"\"\"\n",
    "    printable = set(string.printable)\n",
    "    return ''.join(filter(lambda x: x in printable, text)) \n",
    "#The filter() function is then used with a lambda function to iterate over each character in the input text and keep only those characters that are present in the printable set. \n",
    "#join() method to concatenate the filtered characters back into a single string, effectively removing any non-ASCII characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c1e71451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_header(line):\n",
    "                                           # as we're consolidating broken lines into paragraphs, we want to make sure not to include headers\n",
    "  return not line.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "59913e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#When you load the 'en_core_web_sm' model using the spacy.load() function, you are essentially loading a trained NLP model into your Python code, which can then be used to process text data and perform various NLP tasks. Once the model is loaded, you can use its functionalities, such as tokenization, sentence segmentation, entity recognition, and more, to analyze and extract information from text data in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "259bc689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statements(nlp, text):\n",
    "    \"\"\"\n",
    "    Extracts ESG statements from raw text by removing junk, URLs, etc.\n",
    "    Groups consecutive lines into paragraphs and uses Spacy to parse sentences.\n",
    "    \"\"\"\n",
    "    # remove non ASCII characters\n",
    "    text = remove_non_ascii(text)\n",
    "\n",
    "    lines = []\n",
    "    prev = \"\"\n",
    "    for line in text.split('\\n'):\n",
    "        # aggregate consecutive lines where text may be broken down\n",
    "        # only if next line starts with a space or previous does not end with dot.\n",
    "        if(line.startswith(' ') or not prev.endswith('.')):\n",
    "            prev = prev + ' ' + line\n",
    "        else:\n",
    "            # new paragraph\n",
    "            lines.append(prev)\n",
    "            prev = line\n",
    "\n",
    "    # don't forget left-over paragraph\n",
    "    lines.append(prev)\n",
    "\n",
    "    # clean paragraphs from extra space, unwanted characters, urls, etc.\n",
    "    # best effort clean up, consider a more versatile cleaner\n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "\n",
    "        # removing header number\n",
    "        line = re.sub(r'^\\s?\\d+(.*)$', r'\\1', line)\n",
    "        # removing trailing spaces\n",
    "        line = line.strip()\n",
    "        # words may be split between lines, ensure we link them back together\n",
    "        line = re.sub('\\s?-\\s?', '-', line)\n",
    "        # remove space prior to punctuation\n",
    "        line = re.sub(r'\\s?([,:;.])', r'\\1', line)\n",
    "        # ESG contains a lot of figures that are not relevant to grammatical structure\n",
    "        line = re.sub(r'\\d{5,}', r' ', line)\n",
    "        # remove mentions of URLs\n",
    "        line = re.sub(r'((http|https)://)?[a-zA-Z0-9./?:@-=#]+.([a-zA-Z]){2,6}([a-zA-Z0-9.&/?:@-_=#])*', r' ', line)\n",
    "        # remove multiple spaces\n",
    "        line = re.sub('\\s+', ' ', line)\n",
    "\n",
    "        # split paragraphs into well defined sentences using Spacy\n",
    "        for part in list(nlp(line).sents):\n",
    "            sentences.append(str(part).strip())\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "18769642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while processing https://www.responsibilityreports.com/HostedData/ResponsibilityReports/PDF/LSE_BARC_2021.pdf: EOF marker not found\n",
      "Error occurred while processing https://www.pnc.com/content/dam/pnc-com/pdf/aboutpnc/CorporateResponsibilityReports/PNC_Corporate_Responsibility_Report_2021.pdf: EOF marker not found\n",
      "Error occurred while processing https://about.bankofamerica.com/content/dam/about/pdfs/ESG_GHI_2021_508_secured.pdf: PyCryptodome is required for AES algorithm\n",
      "Error occurred while processing https://www.rbcbluebay.com/globalassets/documents/bluebay-esg-investment-update-june-2021.pdf: EOF marker not found\n",
      "Error occurred while processing https://www.apollo.com/~/media/Files/A/Apollo-V3/documents/apollo-2021-esg-report-final.pdf: EOF marker not found\n"
     ]
    }
   ],
   "source": [
    "esg_articles = esg_urls.copy()\n",
    "esg_articles['content'] = esg_articles['url'].apply(lambda url: extract_content(url))\n",
    "esg_articles = esg_articles[esg_articles['content'].str.len() > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "43ab7b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jp morgan chase</td>\n",
       "      <td>https://www.jpmorgan.com/content/dam/jpmc/jpmo...</td>\n",
       "      <td>2021  \\nENVIRONMENTAL  \\nSOCIAL &amp;  \\nGOVERNAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BNP Paribas</td>\n",
       "      <td>https://cdn-group.bnpparibas.com/uploads/file/...</td>\n",
       "      <td>1\\nBNP PARIBAS / CLIMATE ANALYTICS AND ALIGNM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goldman sachs</td>\n",
       "      <td>https://www.goldmansachs.com/a/2021-sustainabi...</td>\n",
       "      <td>Progress \\nThrough \\nPerformanceSUSTAINABILITY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hsbc</td>\n",
       "      <td>https://www.hsbc.com/-/files/hsbc/investors/hs...</td>\n",
       "      <td>Environmental, social \\nand governance review\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbc</td>\n",
       "      <td>https://www.rbc.com/community-social-impact/_a...</td>\n",
       "      <td>HNW_NRG_B_Bleed_NoMask\\nRoyal Bank of Canada\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>macquarie</td>\n",
       "      <td>https://www.macquarie.com/assets/macq/investor...</td>\n",
       "      <td>52\\nEnvironmental, Social and Governance\\nMacq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lloyds</td>\n",
       "      <td>https://assets.lloyds.com/media/8c362b67-e4a5-...</td>\n",
       "      <td>Environmental, Social \\nand Governance \\nRepor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>santander</td>\n",
       "      <td>https://www.santander.com/content/dam/santande...</td>\n",
       "      <td>ESG Report 2021\\nLooking to the future\\nRespon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>riverstone</td>\n",
       "      <td>https://www.riverstonellc.com/media/1328/river...</td>\n",
       "      <td>Investing  \\nResponsibly\\nRiverstone ESG Repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aberdeen standard</td>\n",
       "      <td>https://www.abrdn.com/docs?documentId=GB-08032...</td>\n",
       "      <td>The Power  \\nof Investment\\nSustainability Rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vanguard</td>\n",
       "      <td>https://www.nl.vanguard/content/dam/intl/europ...</td>\n",
       "      <td>Vanguard’s Report \\non Climate-related \\nImpac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ruffer</td>\n",
       "      <td>https://www.ruffer.co.uk/-/media/ruffer-websit...</td>\n",
       "      <td>Responsible \\nInvestment \\nReport \\n2021\\nCHAR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              company                                                url  \\\n",
       "1     jp morgan chase  https://www.jpmorgan.com/content/dam/jpmc/jpmo...   \n",
       "2         BNP Paribas  https://cdn-group.bnpparibas.com/uploads/file/...   \n",
       "3       goldman sachs  https://www.goldmansachs.com/a/2021-sustainabi...   \n",
       "4                hsbc  https://www.hsbc.com/-/files/hsbc/investors/hs...   \n",
       "7                 rbc  https://www.rbc.com/community-social-impact/_a...   \n",
       "8           macquarie  https://www.macquarie.com/assets/macq/investor...   \n",
       "9              lloyds  https://assets.lloyds.com/media/8c362b67-e4a5-...   \n",
       "10          santander  https://www.santander.com/content/dam/santande...   \n",
       "12         riverstone  https://www.riverstonellc.com/media/1328/river...   \n",
       "13  aberdeen standard  https://www.abrdn.com/docs?documentId=GB-08032...   \n",
       "15           vanguard  https://www.nl.vanguard/content/dam/intl/europ...   \n",
       "16             ruffer  https://www.ruffer.co.uk/-/media/ruffer-websit...   \n",
       "\n",
       "                                              content  \n",
       "1    2021  \\nENVIRONMENTAL  \\nSOCIAL &  \\nGOVERNAN...  \n",
       "2    1\\nBNP PARIBAS / CLIMATE ANALYTICS AND ALIGNM...  \n",
       "3   Progress \\nThrough \\nPerformanceSUSTAINABILITY...  \n",
       "4   Environmental, social \\nand governance review\\...  \n",
       "7   HNW_NRG_B_Bleed_NoMask\\nRoyal Bank of Canada\\n...  \n",
       "8   52\\nEnvironmental, Social and Governance\\nMacq...  \n",
       "9   Environmental, Social \\nand Governance \\nRepor...  \n",
       "10  ESG Report 2021\\nLooking to the future\\nRespon...  \n",
       "12  Investing  \\nResponsibly\\nRiverstone ESG Repor...  \n",
       "13  The Power  \\nof Investment\\nSustainability Rep...  \n",
       "15  Vanguard’s Report \\non Climate-related \\nImpac...  \n",
       "16  Responsible \\nInvestment \\nReport \\n2021\\nCHAR...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esg_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6c19a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statements_udf(content_series, nlp):\n",
    "\n",
    "    statements = []\n",
    "    for content in content_series:\n",
    "        # remove non ASCII characters\n",
    "        text = remove_non_ascii(content)\n",
    "\n",
    "        # split into paragraphs and sentences\n",
    "        lines = []\n",
    "        prev = \"\"\n",
    "        for line in text.split('\\n'):\n",
    "            if(line.startswith(' ') or not prev.endswith('.')):\n",
    "                prev = prev + ' ' + line\n",
    "            else:\n",
    "                lines.append(prev)\n",
    "                prev = line\n",
    "        lines.append(prev)\n",
    "\n",
    "        # clean paragraphs from extra space, unwanted characters, urls, etc.\n",
    "        # best effort clean up, consider a more versatile cleaner\n",
    "        for line in lines:\n",
    "            line = re.sub(r'^\\s?\\d+(.*)$', r'\\1', line)  # removing header number\n",
    "            line = line.strip()  # removing trailing spaces\n",
    "            line = re.sub('\\s?-\\s?', '-', line)  # words may be split between lines, ensure we link them back together\n",
    "            line = re.sub(r'\\s?([,:;.])', r'\\1', line)  # remove space prior to punctuation\n",
    "            line = re.sub(r'\\d{5,}', r' ', line)  # remove numbers with more than 5 digits\n",
    "            line = re.sub(r'((http|https)://)?[-a-zA-Z0-9./?:@=#]+\\\\.([a-zA-Z]){2,6}([a-zA-Z0-9.&/?:@-_=#])*', r' ', line)\n",
    "            line = re.sub('\\s+', ' ', line)  # remove multiple spaces\n",
    "\n",
    "            # split paragraphs into sentences using spacy\n",
    "            for part in list(nlp(line).sents):\n",
    "                sentence = str(part).strip()\n",
    "                if len(sentence) > 100:  # filter out short sentences\n",
    "                    statements.append(sentence)\n",
    "\n",
    "    return statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2fae7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(columns=[\"company\", \"statements\"])\n",
    "for company, content in esg_articles[[\"company\", \"content\"]].values:\n",
    "    statements = extract_statements_udf(content_series=pd.Series([content]), nlp=nlp)\n",
    "    tmp = tmp.append({\"company\": company, \"statements\": statements}, ignore_index=True)\n",
    "\n",
    "esg_statements = tmp.explode(column=\"statements\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d02aba01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>statements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jp morgan chase</td>\n",
       "      <td>2021 ENVIRONMENTAL SOCIAL &amp; GOVERNANCE REPORT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jp morgan chase</td>\n",
       "      <td>Feature: Our Commitment to Racial Equity 21Div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jp morgan chase</td>\n",
       "      <td>It has also shown what companies like ours can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jp morgan chase</td>\n",
       "      <td>Throughout this period of uncertainty, JPMorga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jp morgan chase</td>\n",
       "      <td>We are leveraging capital and expertise across...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8614</th>\n",
       "      <td>ruffer</td>\n",
       "      <td>This financial promotion is issued by Ruffer L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8615</th>\n",
       "      <td>ruffer</td>\n",
       "      <td>Although Ruffer LLPs information providers, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8616</th>\n",
       "      <td>ruffer</td>\n",
       "      <td>None of the ESG Parties makes any express or i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8617</th>\n",
       "      <td>ruffer</td>\n",
       "      <td>None of the ESG Parties shall have any liabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8618</th>\n",
       "      <td>ruffer</td>\n",
       "      <td>Further, without limiting any of the foregoing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              company                                         statements\n",
       "0     jp morgan chase  2021 ENVIRONMENTAL SOCIAL & GOVERNANCE REPORT ...\n",
       "1     jp morgan chase  Feature: Our Commitment to Racial Equity 21Div...\n",
       "2     jp morgan chase  It has also shown what companies like ours can...\n",
       "3     jp morgan chase  Throughout this period of uncertainty, JPMorga...\n",
       "4     jp morgan chase  We are leveraging capital and expertise across...\n",
       "...               ...                                                ...\n",
       "8614           ruffer  This financial promotion is issued by Ruffer L...\n",
       "8615           ruffer  Although Ruffer LLPs information providers, in...\n",
       "8616           ruffer  None of the ESG Parties makes any express or i...\n",
       "8617           ruffer  None of the ESG Parties shall have any liabili...\n",
       "8618           ruffer  Further, without limiting any of the foregoing...\n",
       "\n",
       "[8619 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esg_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ac2b606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_statements.to_csv('esg_statements.txt', sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d6fecaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    # Parse text using spacy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Convert words into their simplest form (singular, present form, etc.)\n",
    "    lemma = []\n",
    "    for token in doc:\n",
    "        if token.lemma_ != '-PRON-':\n",
    "            lemma.append(token.lemma_)\n",
    "    return ' '.join(lemma)\n",
    "\n",
    "\n",
    "\n",
    "#This version of the function uses token.lemma_ instead of token.lemma to access the lemmatized form of the token, and returns a string instead of a tokenized string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "464f0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    gen = gensim.utils.simple_preprocess(sentence, deacc=True) #performs basic text preprocessing, including lowercasing, tokenization, and removing punctuation marks\n",
    "    return ' '.join(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the lemmatize function to each statement in the DataFrame\n",
    "esg_statements['lemma'] = esg_statements['statements'].apply(lemmatize)\n",
    "\n",
    "# Select only the columns we want to keep\n",
    "esg_lemma = esg_statements[['company', 'statements', 'lemma']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61de46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_lemma.to_csv('esg_lemma.txt', sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb9729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_and_company_names(lemma, company_name):\n",
    "    # Parse lemma using spacy\n",
    "    doc = nlp(lemma)\n",
    "    extra=['plc', 'group', 'target',\n",
    "           'track', 'capital', 'holding',\n",
    "           'report', 'annualreport',\n",
    "           'esg', 'bank', 'report',\n",
    "           'annualreport', 'long', 'make','2021 tcfd','2020 2021','https www',\n",
    "          ]\n",
    "    # Create a list of stop words and company names\n",
    "    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    company_name_tokens = company_name.split()                               # tokenize the company name\n",
    "    stop_words.update(company_name_tokens)\n",
    "    stop_words.update(extra)\n",
    "\n",
    "\n",
    "    # Remove stop words and company names from the lemma\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.text.lower() not in stop_words:\n",
    "            filtered_tokens.append(token.text)\n",
    "\n",
    "    # Join the filtered tokens back into a string\n",
    "    filtered_lemma = ' '.join(filtered_tokens)\n",
    "    return filtered_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a663a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the remove_stop_words_and_company_names() function to 'lemma' column in 'esg_statements' DataFrame\n",
    "esg_statements['lemma'] = esg_statements.apply(lambda row: remove_stop_words_and_company_names(row['lemma'],\n",
    "                                                                                               row['company']), axis=1)\n",
    "esg_lemmatized=esg_statements[['company', 'statements', 'lemma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dec1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_lemmatized.to_csv('esg_lemmatized.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b46db-c4cf-4f3e-9e7c-65af35e4c1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = list(stop_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7155c-0ce5-4a0b-a5ce-128cc3bad3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "large_string = ' '.join(esg_lemmatized.lemma)\n",
    "\n",
    "# use 3rd party lib to compute term freq., apply stop words\n",
    "word_cloud = WordCloud(\n",
    "    background_color=\"white\",\n",
    "    max_words=5000, \n",
    "    width=900, \n",
    "    height=700, \n",
    "    stopwords=stop_words, \n",
    "    contour_width=3, \n",
    "    contour_color='steelblue'\n",
    ")\n",
    "\n",
    "# display our wordcloud across all records\n",
    "plt.figure(figsize=(10,10))\n",
    "word_cloud.generate(large_string)\n",
    "plt.imshow(word_cloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bi-gram TF-IDF frequencies\n",
    "bigram_tf_idf_vectorizer = TfidfVectorizer(stop_words=stop_words, ngram_range=(2,2), min_df=10, use_idf=True)\n",
    "bigram_tf_idf = bigram_tf_idf_vectorizer.fit_transform(esg_lemmatized['lemma'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe0767-f33d-4419-990c-fb832cef381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a4cf7-7894-43c6-be07-eb4910ffcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display bigram_tf_idf \n",
    "# Convert bigram_tf_idf to dense matrix\n",
    "dense_matrix = bigram_tf_idf.todense()\n",
    "\n",
    "# Print dense matrix\n",
    "print(dense_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73bc51f-5db3-4dae-b6da-fc9ce3a67c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "words = list(bigram_tf_idf_vectorizer.vocabulary_.keys())\n",
    "\n",
    "# extract our top 10 ngrams\n",
    "total_counts = np.zeros(len(words))\n",
    "for t in bigram_tf_idf:\n",
    "    total_counts += t.toarray()[0]\n",
    "count_dict = (zip(words, total_counts))\n",
    "count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]     #sliced using [0:10] to select only the top 10 entries with the highest total counts.\n",
    "words = [w[0] for w in count_dict]\n",
    "counts = [w[1] for w in count_dict]\n",
    "x_pos = np.arange(len(words)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bdfa6-2560-4957-8606-580ad0aa528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f11ad7-f63c-452a-98bf-da0414c253b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339f4ee-5acd-4e3a-8e70-23706ba8efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657a084-132a-4f48-8a22-370ad3171362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 10 ngrams\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(title='10 most common bi-grams')\n",
    "sns.barplot(x=words, y=counts, palette='Blues_r')\n",
    "plt.xticks(x_pos, words, rotation=90) \n",
    "plt.xlabel('bi-grams')\n",
    "plt.ylabel('tfidf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23474b1-80fe-4c92-a3fa-48fcd1ee83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f1a0f-ec31-4797-8406-4043ac36d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc135c-1987-4247-b009-fcf4d8a7b012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Topic modelling\n",
    "word_tf_vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=(1,1))                    #counting the number of occurrences of each word in each document.\n",
    "word_tf = word_tf_vectorizer.fit_transform(esg_lemmatized.lemma)\n",
    "# serialize stopwords \n",
    "json_data = json.dumps([a for a in stop_words], indent=2)\n",
    "f = open(\"C:\\\\Users\\\\User\\\\ESG\\\\stopwords.json\", \"w\")\n",
    "f.write(json_data)\n",
    "f.close()\n",
    "  \n",
    "# track experiment on MLflow\n",
    "with mlflow.start_run(run_name='topic_modelling'):                                            #how many args could we pass ?\n",
    "  \n",
    "  # Train a LDA model with 9 topics\n",
    "  lda = LDA(random_state = 42, n_components = 9, learning_decay = .3)\n",
    "  lda.fit(word_tf) # trains the LDA model on the word frequency matrix word_tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d2d9e-c540-4e3c-8e69-e8ba02331ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  # Log model \n",
    "  mlflow.sklearn.log_model(lda, \"model\")\n",
    "  mlflow.log_param('n_components', '9')\n",
    "  mlflow.log_param('learning_decay', '.3')\n",
    "  mlflow.log_metric('perplexity', lda.perplexity(word_tf))\n",
    "  mlflow.log_artifact(\"C:\\\\Users\\\\User\\\\ESG\\\\stopwords.json\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3058afbb-aa6f-4de3-9768-f6f9a3885ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # retrieve run ID to attach topic name later\n",
    "  lda_run_id = mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972ed28-02a0-4a96-9b28-6f23a5b0ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top N words describing each of our 9 topics\n",
    "\n",
    "def top_words(model, feature_names, n_top_words):\n",
    "    topics_words = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        \n",
    "        words = []\n",
    "        for i in topic.argsort()[:-n_top_words-1:-1]:\n",
    "            if len(feature_names[i]) > 1:\n",
    "                words.append(feature_names[i])\n",
    "            else:\n",
    "                words.append('')\n",
    "            \n",
    "        topics_words.append(words)\n",
    "        df = pd.DataFrame(topics_words)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0cef8-ca57-4dbc-a7d3-a57c5ec38d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display topics keywords for inspection and for us to label topics\n",
    "# Vectorize words using TF-IDF Vectorizer\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_vectorizer.fit(esg_lemmatized.lemma)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "display(top_words(lda, tf_feature_names, 15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289fac77-78a7-47cb-91d4-f0e3718c2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define topic names\n",
    "# We estimated our topics to be described around the following themes\n",
    "\n",
    "topic_names = [\n",
    "    'green energy',\n",
    "    'focus customer',\n",
    "  'value employees',\n",
    "  'strong governance', \n",
    "  'support community',\n",
    "  'company transformation',\n",
    "  'ethical investments',\n",
    "  'sustainable finance',\n",
    "  'code of conduct',\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71989156-2e4e-4292-8df5-a74934577430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize topic names\n",
    "json_data = json.dumps(topic_names, indent=2)\n",
    "f = open(\"C:\\\\Users\\\\User\\\\ESG\\\\topics.json\", \"w\")\n",
    "f.write(json_data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0c294-9d3f-4691-a2dc-c3b6f789393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach topics name to LDA model on mlflow\n",
    "# we do not wish to re-open run_id and therefore alter start / end time\n",
    "# instead, we log artifact to existing run\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.log_artifact(lda_run_id, \"C:\\\\Users\\\\User\\\\ESG\\\\topics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14a0ed-4e8b-4c7b-b6b9-4f44a1e03f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e1c91-d384-4d42-950c-8084318b522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display topics\n",
    "# We ensure relevance of our topics using simple wordcloud visualisation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def word_cloud(model, tf_feature_names, index):\n",
    "    \n",
    "    imp_words_topic=\"\"\n",
    "    comp = model.components_[index]\n",
    "    vocab_comp = zip(tf_feature_names, comp)\n",
    "    sorted_words = sorted(vocab_comp, key = lambda x:x[1], reverse=True)[:50]\n",
    "    \n",
    "    for word in sorted_words:\n",
    "        imp_words_topic = imp_words_topic + \" \" + word[0]\n",
    "    \n",
    "    return WordCloud(\n",
    "        background_color=\"white\",\n",
    "        width=600, \n",
    "        height=600, \n",
    "        contour_width=3, \n",
    "        contour_color='steelblue'\n",
    "    ).generate(imp_words_topic)\n",
    "    \n",
    "topics = len(lda.components_)\n",
    "fig = plt.figure(figsize=(20, 20 * topics / 3))\n",
    "\n",
    "# Display wordcloud for each extracted topic\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    ax = fig.add_subplot(topics,3, i + 1)\n",
    "    ax.set_title(topic_names[i], fontsize=20)\n",
    "    wordcloud = word_cloud(lda, tf_feature_names, i)\n",
    "    ax.imshow(wordcloud)\n",
    "    ax.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee526399-e0b9-4ac4-908c-ce7d3a196b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attach topic distribution to each ESG statement\n",
    "# score our original dataset to attach topic distribution to each ESG statement\n",
    "transformed = lda.transform(word_tf)\n",
    "\n",
    "# find principal topic from distribution...\n",
    "a = [topic_names[np.argmax(distribution)] for distribution in transformed]\n",
    "\n",
    "# ... with associated probability\n",
    "b = [np.max(distribution) for distribution in transformed]\n",
    "\n",
    "# consolidate LDA output into a handy dataframe \n",
    "df1 = esg_lemmatized[['company', 'statements', 'lemma']]\n",
    "df2 = pd.DataFrame(zip(a,b,transformed), columns=['topic', 'probability', 'probabilities'])\n",
    "esg_group = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# display dataframe\n",
    "display(esg_group[['company', 'lemma', 'topic', 'probability']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da4653-3375-4fe5-b407-aae5ec0d6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attach topic distribution to each ESG statement\n",
    "# score our original dataset to attach topic distribution to each ESG statement\n",
    "transformed = lda.transform(word_tf)\n",
    "\n",
    "# find principal topic from distribution...\n",
    "a = [topic_names[np.argmax(distribution)] for distribution in transformed]\n",
    "\n",
    "# ... with associated probability\n",
    "b = [np.max(distribution) for distribution in transformed]\n",
    "\n",
    "# consolidate LDA output into a handy dataframe \n",
    "df1 = esg_lemmatized[['company', 'lemma', 'statements']]\n",
    "df2 = pd.DataFrame(zip(a,b,transformed), columns=['topic', 'probability', 'probabilities'])\n",
    "esg_group = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# display dataframe\n",
    "display(esg_group[['company', 'lemma', 'topic', 'probability']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e54c6e-32d1-43e4-926d-d752463b8c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c8cf6-2111-4d2b-a55b-974bc91e86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare companies core ESG initiatives\n",
    "# create a simple pivot table of number of occurence of each topic across organisations\n",
    "\n",
    "esg_focus = pd.crosstab(esg_group.company, esg_group.topic)\n",
    "\n",
    "# scale topic frequency between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "# normalize pivot table\n",
    "esg_focus_norm = pd.DataFrame(scaler.fit_transform(esg_focus), columns=esg_focus.columns)\n",
    "esg_focus_norm.index = esg_focus.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2342c31-4270-40f8-bdda-1298cc7a624d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "esg_focus_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a1276-d726-45b3-9a4f-f5771e16efbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "esg_focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f1a926-b230-4c96-8109-1b67154f389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap, showing main area of focus for each FSI across topics we learned\n",
    "sns.set(rc={'figure.figsize':(10,5)})\n",
    "sns.heatmap(esg_focus_norm, annot=False, linewidths=.5, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d21f38-9c28-40e8-ace5-e0a56640b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show distribution of topic probability\n",
    "\n",
    "# not every statement follows a well defined topic\n",
    "\n",
    "# some statements may be more generic and span across multiple themes\n",
    "\n",
    "esg_group.probability.hist(bins=50, figsize=(8,5), color='steelblue')\n",
    "\n",
    "# plot distribution of main topic proability\n",
    "plt.axvline(0.89, color='coral', linestyle='--')\n",
    "plt.title('Primary topic distribution')\n",
    "plt.xlabel('probability')\n",
    "plt.ylabel('density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbfe5a2-dcea-4233-b780-e0b76febcebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_group.probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5019f3d-a810-4c72-93af-7e8b171a406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve key statements for each topic\n",
    "\n",
    "# extract statements relevant to a given topic\n",
    "\n",
    "topic_discussions = esg_group[esg_group['topic'] == 'green energy']\n",
    "\n",
    "# as specified in probability distribution, we want only specific topics and not general discussions\n",
    "topic_discussions = topic_discussions[topic_discussions['probability'] > 0.89]\n",
    "\n",
    "# access more specific topics first\n",
    "\n",
    "topic_discussions = topic_discussions.sort_values('probability', ascending=False)\n",
    "\n",
    "rows = [] \n",
    "for i, row in topic_discussions.iterrows():\n",
    "  rows.append([row.company, row.probability, row.statements])\n",
    "\n",
    "# display dataframe of statements for selected topic of interest\n",
    "display(pd.DataFrame(rows, columns=['company', 'probability', 'statement']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb515b-c45e-4104-88a9-284cded5c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP3: Key ESG initiatives\n",
    "#identifier les declarations spécific à chaque entreprise à partir des proba de LDA en utilisant KMeans : clustering chaque declaration en fct de leur similitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4138a3-1dc1-4ccd-887b-50a00676acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6166b-4a3a-49aa-b1dd-61e798878a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1 déterminier le nombre optimale des clusters K avec ELBOW METHOD\n",
    "# we extract our probabilities distribution as input vectors for KMeans\n",
    "X_train = list(esg_group.probabilities)\n",
    "\n",
    "# nevertheless, we still want to ensure relavance of our clustering using the simple \"elbow method\"\n",
    "# we capture the sum of squared distance of each point to their closest center for different values of k\n",
    "wsses = []\n",
    "for k in [5, 8, 10, 20, 30, 50, 80, 100]:\n",
    "  kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "  kmeans.fit(X_train)\n",
    "  wsse = np.sum([np.min(x)**2 for x in kmeans.transform(X_train)]) \n",
    "  wsses.append([k, wsse])\n",
    "  \n",
    "#we simply plot the WSSE against K to find optimal K value\n",
    "wsse_df = pd.DataFrame(wsses, columns=['k', 'wsse'])\n",
    "display(wsse_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612b15a-e837-4049-92bd-52886dbd99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the WSSE against K to find optimal K value\n",
    "plt.plot(wsse_df['k'], wsse_df['wsse'])\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Sum of Squared Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388430c6-5fe7-4646-aba0-8222df5706f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K is aroud 15 - 20 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615dbcd4-7867-4f4c-94cb-3c92f3867684",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093db6b4-45ec-4b01-9f93-4e0ae35900c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#grouper les déclarations en clusters et déterminer la plus proche distance\n",
    "# track experiment on MLflow\n",
    "with mlflow.start_run(run_name='clustering'):\n",
    "  \n",
    "  # we train our KMeans model trained with the appropriate value for K\n",
    "  kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "  kmeans.fit(X_train)\n",
    "  \n",
    "  # Log model \n",
    "  mlflow.sklearn.log_model(kmeans, \"model\")\n",
    "  mlflow.log_param('n_clusters', '15')\n",
    "  mlflow.log_metric('wsse', np.sum([np.min(x)**2 for x in kmeans.transform(X_train)]))\n",
    "  \n",
    "  # Retrieve experiment ID\n",
    "  cluster_run_id = mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f172626-147a-4e58-a714-807047444519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign statements to closest clusters\n",
    "# find the minimum distance for each point to their closest cluster\n",
    "y_dist = [np.min(x) for x in kmeans.transform(X_train)]                          #calcule la distance minimale entre chaque point\n",
    "dist_df = pd.DataFrame(zip(y_dist), columns=['distance'])\n",
    "esg_group_dist = pd.concat([esg_group, dist_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb42dc3-28af-46fc-baa8-3eda2074ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_group_dist[['company', 'lemma', 'topic','probability','distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295bf8a-1627-4b72-9da0-d4f6833b315c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "esg_group_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85dc82-7f49-4d58-a0de-740aefad804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_group_dist.to_csv('esg_reports.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259ef83-2f1a-40a4-97c9-9db86ea6903a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install delta-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913568ff-db94-4ea7-bc1d-9eafba91d5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6aad0f-b793-46a8-9897-8ca51fe93d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NLP_ESG\").getOrCreate()\n",
    "\n",
    "df = pd.DataFrame(esg_group_dist)\n",
    "# create a SQLite engine\n",
    "engine = create_engine('sqlite:///esg.db', echo=False)\n",
    "\n",
    "df.to_sql('reports', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e41b34-2c2a-4828-8174-ff09db611d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebc820-6ec9-41f5-90c9-dc4deee0c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        t.company,\n",
    "        t.topic,\n",
    "        t.statement\n",
    "       \n",
    "    FROM (\n",
    "        SELECT \n",
    "            e.company,\n",
    "            e.topic,\n",
    "            e.probability,\n",
    "            e.distance,\n",
    "            LOWER(e.statements) AS statement,\n",
    "            dense_rank() OVER (PARTITION BY e.company, e.topic ORDER BY e.distance DESC) as rank\n",
    "        FROM reports e\n",
    "    ) t\n",
    "    WHERE t.rank = 1\n",
    "    AND t.topic IN ('green energy')\n",
    "    ORDER BY company, topic, rank\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sql=query, con=engine.connect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde95b8-4ef9-4186-a76b-d71869b6df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49fec3-6aa9-4451-868e-3460c4a0db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH ranked AS (\n",
    "  SELECT \n",
    "    e.topic, \n",
    "    e.statements, \n",
    "    e.company,\n",
    "    dense_rank() OVER (PARTITION BY e.company, e.topic ORDER BY e.probability DESC) as rank\n",
    "  FROM reports e\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  t.topic,\n",
    "  t.statements\n",
    "FROM ranked t\n",
    "WHERE t.company = 'BNP Paribas' \n",
    "AND t.rank = 1\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(sql= text(query), con=engine.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a06905-1b27-4749-99a9-8183629a1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a94aae-2f01-4401-9beb-e619577848a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Sélectionner les colonnes pertinentes\n",
    "relevant_columns = [\"topic\", \"company\", \"probability\"]\n",
    "esg_scores = esg_group_dist[relevant_columns]\n",
    "\n",
    "# Grouper les données par \"topic\" et \"company\" et calculer la somme des probabilités pour chaque groupe\n",
    "esg_scores = esg_scores.groupby([\"topic\", \"company\"]).agg(esg=(\"probability\", \"sum\")).reset_index()\n",
    "\n",
    "# Ajouter une colonne \"rank\" représentant le classement des organisations en fonction de \"esg\", en les ordonnant par ordre croissant\n",
    "esg_scores[\"rank\"] = esg_scores[\"esg\"].rank(ascending=True)\n",
    "\n",
    "# Calculer le score ESG en divisant le classement par le nombre total d'organisations et en le multipliant par 100\n",
    "esg_scores[\"esg\"] = (esg_scores[\"rank\"] / len(esg_scores)) * 100\n",
    "\n",
    "# Arrondir le résultat du calcul précédent à un entier\n",
    "esg_scores[\"esg\"] = esg_scores[\"esg\"].round().astype(int)\n",
    "\n",
    "# Sélectionner les colonnes \"company\", \"topic\" et \"esg\" pour les résultats finaux\n",
    "esg_score = esg_scores[[\"company\", \"topic\", \"esg\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612ed24-6b4c-4a87-8152-c1803c26e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "relevant_columns = [\"topic\", \"company\", \"probability\"]\n",
    "esg_scores = esg_group_dist[relevant_columns]\n",
    "\n",
    "esg_scores = esg_scores.groupby([\"topic\", \"company\"]).agg(esg=(\"probability\", \"sum\")).reset_index()\n",
    "\n",
    "esg_scores[\"rank\"] = esg_scores[\"esg\"].rank(ascending=True)\n",
    "\n",
    "esg_scores[\"esg\"] = (esg_scores[\"rank\"] / len(esg_scores)) * 100\n",
    "\n",
    "esg_scores[\"esg\"] = esg_scores[\"esg\"].round().astype(int)\n",
    "\n",
    "esg_score = esg_scores[[\"company\", \"topic\", \"esg\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604b266-96b8-4f93-9a4b-115dca1ebf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c11924-4171-4e95-9024-efd471884a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_score.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab116e-c7a1-4ad9-bff2-6dd77eb7034f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transposer les données pour avoir les entreprises en index et les topics en colonnes\n",
    "esg_score_pivot = esg_score.pivot(index='company', columns='topic', values='esg')\n",
    "# Tracer un graphique en barres pour chaque entreprise et chaque topic\n",
    "esg_score_pivot.plot(kind='bar')\n",
    "\n",
    "# Ajouter des décorations à la charte\n",
    "plt.xlabel('Entreprise', fontsize=12)\n",
    "plt.ylabel('Score ESG', fontsize=12)\n",
    "plt.title('Scores ESG par entreprise et par topic', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Topic')\n",
    "\n",
    "# Afficher la charte\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708a468-2837-447d-ac72-e1656220cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Tri des scores des entreprises pour chaque topic en ordre croissant\n",
    "esg_score_sorted = esg_score.sort_values(by='esg')\n",
    "\n",
    "# Création du graphique interactif\n",
    "fig = go.Figure()\n",
    "\n",
    "# Boucle sur chaque topic\n",
    "for topic in esg_score['topic'].unique():\n",
    "    # Filtrage des scores pour le topic spécifique\n",
    "    scores_topic = esg_score_sorted[esg_score_sorted['topic'] == topic]\n",
    "    \n",
    "    # Ajout d'une trace pour le topic\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=scores_topic['company'],\n",
    "        y=scores_topic['esg'],\n",
    "        name=topic\n",
    "    ))\n",
    "\n",
    "# Ajout des décorations au graphique\n",
    "fig.update_layout(\n",
    "    title='Scores ESG des entreprises par topic (tri croissant)',\n",
    "    xaxis=dict(title='Entreprise'),\n",
    "    yaxis=dict(title='Score ESG'),\n",
    "    barmode='group',\n",
    "    legend_title='Topic',\n",
    "    width=1300,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Affichage du graphique interactif\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23918d08-2f8a-44d9-8683-37de8ab38dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Transposer les données pour avoir les entreprises en index et les topics en colonnes\n",
    "esg_score_pivot = esg_score.pivot(index='company', columns='topic', values='esg')\n",
    "\n",
    "# Tracer une heatmap pour visualiser les scores ESG par entreprise et par topic\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(esg_score_pivot, cmap='Blues', annot=True, fmt=\"d\")\n",
    "\n",
    "# Ajouter des décorations à la charte\n",
    "plt.xlabel('Topic', fontsize=12)\n",
    "plt.ylabel('Entreprise', fontsize=12)\n",
    "plt.title('Scores ESG par entreprise et par topic', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Afficher la charte\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef8d77-b062-49b0-a856-45438cb128d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Transposer les données pour avoir les entreprises en index et les topics en colonnes\n",
    "esg_score_pivot = esg_score.pivot(index='company', columns='topic', values='esg')\n",
    "\n",
    "# Créer une figure de heatmap interactive avec Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=esg_score_pivot.values,\n",
    "    x=esg_score_pivot.columns,\n",
    "    y=esg_score_pivot.index,\n",
    "    colorscale='Blues',\n",
    "    hovertemplate='Entreprise: %{y}<br>Topic: %{x}<br>Score ESG: %{z}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Ajouter des décorations à la figure\n",
    "fig.update_layout(\n",
    "    title='Scores ESG par entreprise et par sujet',\n",
    "    xaxis=dict(title='Topic'),\n",
    "    yaxis=dict(title='Entreprise')\n",
    ")\n",
    "\n",
    "# Afficher la figure interactive\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7862762-fe2b-4264-8f13-2172c6b12f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Créer une copie du DataFrame esg_scores\n",
    "esg_scores_copy = esg_scores.copy()\n",
    "\n",
    "# Grouper les \"topic\" par \"company\" et calculer la moyenne de la colonne 'esg' pour chaque groupe\n",
    "esg_scores_copy = esg_scores_copy.groupby(\"company\").agg(esg=(\"esg\", \"mean\")).reset_index()\n",
    "\n",
    "# Ajouter une colonne 'sum' contenant la somme des scores agrégés\n",
    "esg_scores_copy['sum'] = esg_scores_copy['esg'].sum()\n",
    "\n",
    "# Définir l'index du DataFrame sur la colonne 'company'\n",
    "esg_scores_copy = esg_scores_copy.set_index('company')\n",
    "\n",
    "# Trier les données selon la colonne 'sum' par ordre décroissant\n",
    "esg_scores_copy = esg_scores_copy.sort_values('sum', ascending=False)\n",
    "\n",
    "# Supprimer la colonne 'sum' du DataFrame\n",
    "esg_scores_copy = esg_scores_copy.drop('sum', axis=1)\n",
    "\n",
    "# Tracer un graphique en barres des scores ESG par entreprise\n",
    "colors = [\"#3366cc\", \"#dc3912\", \"#ff9900\", \"#109618\", \"#990099\"]\n",
    "esg_scores_copy.plot(kind='bar', legend=False, color=colors)\n",
    "\n",
    "plt.xlabel('Entreprise', fontsize=12)\n",
    "plt.ylabel('Score ESG', fontsize=12)\n",
    "plt.title('Scores ESG par entreprise', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Afficher la charte\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26810860-a616-4e40-8029-0684ec0eafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55ec84-36d9-4136-a5cf-8a6328601a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
